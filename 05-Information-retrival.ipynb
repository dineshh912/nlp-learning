{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informaton Extration\n",
    "\n",
    "    Task of extracting relevant information from large text documents. In most cases, extracting information that has fixed pattern like address, phone numbere , dates etc., Exteracting information other than this need more advanced language processing.\n",
    "    \n",
    "    * Tagging news and other contents\n",
    "    * Chatbots, (it needs to identify location, cafe)\n",
    "    * Application in social media (Traffic update, disaster relief efforts)\n",
    "    * Extract data from forms and receipts\n",
    "    * OCR\n",
    "\n",
    "* Keyphrase Extraction\n",
    "* Named entity recognition\n",
    "* Named entity disambiguation and linking\n",
    "* Relation extraction\n",
    "* Event extraction\n",
    "* Temporal information (Extract information about time and date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Piprline for Information Extraction\n",
    "    \n",
    "    The general pipeline for IE needed fine-grained NLP proceess. To identify named entities we need to know part of speech tags of words. Relating multiple reference to the same entity we would need co-reference solutions.\n",
    "    \n",
    "    Raw text => sentence segmentaion => Word Tokenization (Keypharse)  => Part of speech tagging(extraction, NER) => suntactic parsing => coreferecnce resolution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword and pharse Extraction\n",
    "    Task concerned with extrcting important words and phrases that capture the gist of the text from given text document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KPE algorithms are based on the idea of representing the words and phrases in a text as nodes in a weighted graph where the weight indicates the importance of that keyphrase. Keyphrases are then identified based on how connected they are with the rest of the graph. The top-N important nodes from the graph are then returned as keyphrases. Important nodes are those words and phrases that are frequent\n",
    "enough and also well connected to different parts of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "textacy python library build on top of spacy, contain common graph based keyword and phrase extraction algotithm. Text rank algorithm, SG Rank Algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import textacy.ke\n",
    "from textacy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a spacy model, which will be used for all further processing.\n",
    "en = textacy.load_spacy_lang(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = open(path+'./Data/nlphistory.txt').read()\n",
    "\n",
    "#convert the text into a spacy document.\n",
    "doc = textacy.make_spacy_doc(mytext, lang=en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textacy.ke.textrank(doc, topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the keywords using TextRank algorithm, as implemented in Textacy.\n",
    "print(\"Textrank output: \", [kps for kps, weights in textacy.ke.textrank(doc, normalize=\"lemma\", topn=5)])\\\n",
    "#Print the key words and phrases, using SGRank algorithm, as implemented in Textacy\n",
    "print(\"SGRank output: \", [kps for kps, weights in textacy.ke.sgrank(doc, topn=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To address the issue of overlapping key phrases, textacy has a function: aggregage_term_variants.\n",
    "#Choosing one of the grouped terms per item will give us a list of non-overlapping key phrases!\n",
    "terms = set([term for term,weight in textacy.ke.sgrank(doc)])\n",
    "print(textacy.ke.utils.aggregate_term_variants(terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A way to look at key phrases is just consider all noun chunks as potential ones. \n",
    "#However, keep in mind this will result in a lot of phrases, and no way to rank them!\n",
    "\n",
    "print([chunk for chunk in textacy.extract.noun_chunks(doc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thnings to keep in mind when doing keyphrase extraction\n",
    "\n",
    "* Extracting n-gram and building graph is sensitive to document length. first m% and last m%.\n",
    "* Since each keyphrase is independently ranked, some time end up seeing overlaping keypharse. use cosine similarity between top rank and choose the one most similar.\n",
    "* Seeing counter productive patterns.\n",
    "* Imporoper text extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight of webpage = (1-damping factor) + d * sum(1/number of outbound lings)inbound links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple approach to build NER is to maintain large collection of person/org/location that are relevant to the task in hand. NER is traditionally modeled as a sequence classification problem. Conditional random fields is one of popular sequence classifier training algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
